## 1.1 Understanding an image

### Grid-like representation

A 2D image can be represented as a rectangular grid, composed of many square cells, called pixels.

*How do these pixels look like?*
 
Just try to imagine a chessboard:


![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/chessboard-e1418134328784.jpg)

Just like the black and white squares on the chessboard, pixels are nicely aligned in straight lines, both horizontally and vertically. We will refer to the horizontal ones as rows and to the vertical ones as columns. It is easy to see that a chessboard has 8 rows and 8 columns.  

*But can you guess how many rows and columns of pixels this image has?* 

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/small_spiderman.jpg)

To find this out using Python and OpenCV:  

1) Save the image in the folder where you wish to run your Python code.  
2) **Import OpenCV library** in your Python interpreter or .py file (if you are not familiar with running Python code, just look it up, it should be pretty easy).

```python
import cv2
```

3) Load the image in memory (we will refer to this operation as **reading an image**).

```python
image = cv2.imread('<replace_with_image_name>.jpg')
```

4) **Print the image dimensions**.

```python
print image.shape
```

The program should print ```(232, 223, 3)```. The first two numbers are the number of rows and number of columns. So, 232 x 223 = 51736 pixels in total. For now, don't worry about the third number, it represents the number of colors or, more formally, the number of color channels. We will talk about it in the last section.

### Identifying pixels

Now that you know how to find the number of pixels in an image, *how do you differentiate between them?*

First of all through their address. In real life we use street names, house numbers, city, country etc. Pixels could also be seen as having a street name and a house number.

Street Name = *How many rows are there upwards of the pixel?*  
House Number = *How many columns are there to the left of the pixel?*

A pixel location is formally defined as a pair (row, column), both indexed from 0 (their numbering starts from 0, instead of 1). See if you can guess the location of the red, green and blue pixels on the following grid.

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/street_house.jpg)

The right answers are:  
Red pixel at (3,5)  
Green pixel at (13,8)  
Blue pixel at (10,21)

In Python, for accessing a **pixel at location** ```(row, column)```, we would have to specify the image that we are referring to, and the row and column in square brackets. For example, the **pixel in the center** of the image would be accessed as follows:

```python
import cv2

image = cv2.imread('<replace_with_image_name>.jpg')
no_rows = image.shape[0]
no_cols = image.shape[1]

# Remember that image.shape returns (no_rows, no_cols, no_channels)
# [0] fetches the first number in brackets, [1] - the second one and so on

row = no_rows/2
col = no_cols/2
print image[row, col]
```

If you run this on the image with Spiderman, the script should print ```[ 63  75 141]```. 

*What color do you expect it to have?*

We can visualize the subimage that contains this only one pixel. Generally, if you want to **crop a rectangular portion** with top-left pixel at ```(start_row, start_col)``` and bottom-right pixel at ```(end_row, end_col)```, you would use:

```python
sub_image = image[start_row:end_row + 1, start_col:end_col + 1]
```

and for our particular case:

```python
pixel_image = image[row:row+1, col:col+1]
```

Because this is just a single-pixel image, it is more difficult to visualize, so I recommend **resizing the image** before displaying it. This can be done as follows:

```python
desired_no_rows = 100
desired_no_cols = 100
pixel_image = cv2.resize(pixel_image, (desired_no_cols, desired_no_rows))
```

Now, if you just want to **display the image** obtained, there is the ```cv2.imshow(window_name, image)``` function, which is perfect especially for debugging, when you change an image a number of times and you want to make sure that you are doing the right thing after each step.

For **writing an image** to disk, you would use the ```cv2.imwrite(image_name, image)``` function.

Code for our case:

```python
cv2.imshow('This looks like one pixel', pixel_image)
cv2.waitKey() # For resuming running the code once a key is pressed
cv2.imwrite('pixel.png', pixel_image)
```

And the pixel that I got is this one

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/pixel.png)

Looks reddish, which makes sense because the center of the image falls on a red patch from Spiderman's costume.

Another useful tool when analyzing images is the **iteration through every pixel**. This might turn out helpful in finding pixels or regions with certain properties, or in couting certain events that occur in the image.

**Row by row** (one street at a time):

```python
no_rows = image.shape[0]
no_cols = image.shape[1]
for row in range(no_rows):
	for col in range(no_cols):
		print image[row, col], 'at row', row, 'column', col
```

**Column by column** (one house number at a time):

```python
no_rows = image.shape[0]
no_cols = image.shape[1]
for col in range(no_cols):
	for row in range(no_rows):
		print image[row, col], 'at row', row, 'column', col
```

### Color representation

Let us get back to the chessboard analogy. Each cell was either black or white. Pixels are the same, but instead of just 2 possible values to describe one pixel

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/blackwhite.jpg) {0 = black, 1 = white}

we have 256 possibilities for in-between, transitional colors for grayscale images 

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/grayscale.jpg) {0 = black, 1, 2, ..., 128 = gray, ..., 255 = white}

and 256 x 256 x 256 possibilities for colored(BGR) images.

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/blue_transition.jpg)
x (256 variations in the strength of blue)

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/green_transition.jpg)
x (256 variations in the strength of green)

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/red_transition.jpg)   (256 variations in the strength of red)

So the color of pixels can be represented in a 3-dimensional space.  
*Remember ```[ 63  75 141]```?*  
The description of the pixel in the center.  
*And the third number in ```(232, 223, 3)```?*  
Which showed the number of color channels.  

Well, one component (axis) is to measure the strength of blue(63), one to measure the strength of green(75) and one to measure the strength of red(141). It turns out that combinations of these 3 colors are enough to create most of the visually perceivable colors by humans. Thus, the BGR color space can be viewed as a cube, where 3 opposite points represent blue, green and red. All the other points represent combinations of these 3 core colors. 

![alt](http://www.visualwisdoms.com/wp-content/uploads/2014/12/black_background-e1418220398192.jpg)

Where blue(255,0,0) and red(0,0,255) meet, we get magenta(255,0,255).  
Where red(0,0,255) and green(0,255,0) meet, we get yellow(0,255,255).  
Where green(0,255,0) and blue(255,0,0) meet, we get cyan(255,255,0).

*What can you notice about colors in the BGR color space?*

Their components are summed up independently.

*What BGR components do you think black has?*  
*What BGR components do you think white has?*

Have a look at the highlighted region in the image with Spiderman... 

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/highlighted.jpg)

...put under the microscope

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/BGR.png)

[Source code to reproduce this effect for any image] (https://gist.github.com/2b97dd6bf6b54cfc7bb0)

If you look closely, you will notice that I only used black, blue, green and red pixels. Therefore no yellow and no white. They are simply an illusion. Feel free to inspect the white regions and see that white is created by strong blue, strong green and strong red. On the other hand, black is the result of the absence of blue, green and red components. This is why the BGR color space is called additive. The more color you add, the brighter the result is.

Another way to come to the same conclusion is to display **one component at a time**. That is, if I want to see the green component of an image, I'll simply make the other two components equal zero. And the same with blue and green independently.

```python
blue_component = image.copy() 
green_component = image.copy()
red_component = image.copy()

# First copy image into 3 separate images
# Then make other components equal 0
# Can use the code for iterating an image

no_rows = image.shape[0]
no_cols = image.shape[1]

# Isolate blue component
for row in range(no_rows):
	for col in range(no_cols):
		blue = blue_component[row, col, 0]
		blue_component[row, col] = (blue, 0, 0)
		
cv2.imwrite('blue.jpg', blue_component)
		
# Isolate green component
for row in range(no_rows):
	for col in range(no_cols):
		green = green_component[row, col, 1]
		green_component[row, col] = (0, green, 0)

cv2.imwrite('green.jpg', green_component)
		
# Isolate red component
for row in range(no_rows):
	for col in range(no_cols):
		red = red_component[row, col, 2]
		red_component[row, col] = (0, 0, red)
		
cv2.imwrite('red.jpg', red_component)

```

And the result is:

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/all.jpg)

The last image is in a different colorspace, called grayscale. We have seen that this space has only 256 variations of light intensity (or the color gray). Having just one component (in this case the intensity component) can turn out very convenient, because it can enable us to view an image as a landscape, which can provide many valuable intuitions for certain image processing tasks.

**Conversion from BGR to grayscale**:

```python
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
```

Viewed from above it is very similar to the initial image
![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/ssl3-e1418402039223.png)  
From the sides we can start seeing the dark spots as valleys
![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/ssl0-e1418402065142.png)  
And the white spots as mountains, peaks or plateaus
![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/ssl2-e1418402024265.png)  
Transitions can be smooth or abrupt and help us distinguish borders and regions
![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/ssl1-e1418402053664.png)  


TO-DO:
- 2 more exercises - average, swap color components
- review from Andrei - sharing, tags, metadata


### Summary

After reading this article you should know or keep in mind the following:

1. How images have a **grid**-like representation, with small square cells named **pixels**.

2. Using **cv2.imread** to store image in memory.

3. Using **shape** to get image dimensions.

4. Using **cv2.imshow** to display an image, good for debugging purposes.

5. Using **cv2.imwrite** to save an image to disk.

6. Getting the **pixel** at a specific **location**, given by **row** and **column**.

7. **Iterating** through an image.

8. **Extracting** a rectangular region from an image.

9. Using **cv2.resize** to adapt an image to certain dimensions.

10. Color representation: **grayscale** vs. **BGR**.

11. Using **cv2.cvtColor** to convert between different color spaces.

12. **Separation** of the blue, green and red **components** in BGR images.

13. **Landscape** representation of grayscale images.

### Exercises

1.. **Mirror the Image**

Using the iteration process of an image, flip an image around the vertical axis. Now flip it around the horizontal axis. If you are already familiar with writing such for loops, note that you can use the 

```cv2.flip(image, flipCode)``` function.

Image:

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/resized_car.jpg)

Vertical flip:

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/resized_vertical_flip.jpg)

Horizontal flip:

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/resized_horizontal_flip.jpg)

[Solution](https://github.com/perticascatalin/1.1-Understanding-an-Image/blob/master/exercises/mirror.py)

2.. **Make a Puzzle**

Write a method that first divides the image into square blocks with a given length(a certain number of pixels on each side). To make sure each block contains the same number of pixels from the initial image, adjust the image dimensions to a multiple of the requested length. Your method should then scramble the blocks in a random or different order. To make sure you correctly divide the image into blocks, add borders to them before merging them back together. You could use the 

```cv2.copyMakeBorder(image, pixels_on_top, pixels_on_bottom, pixels_on_left, pixels_on_right)``` function.

Image:

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/resized_car.jpg)

Example result (60 pixels):

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/60_scrambled_resized_car.jpg)

Example result (30 pixels):

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/30_scrambled_resized_car.jpg)

Example result (15 pixels):

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/15_scrambled_resized_car.jpg)

[Solution](https://github.com/perticascatalin/1.1-Understanding-an-Image/blob/master/exercises/puzzle.py)

3.. **Replace by the Average Pixel**

Write a method that replaces a given rectangular region specified by the top-left pixel and bottom-right pixel with the average of the pixels contained.

Image:

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/resized_car.jpg)

Example result (region consisting of top 15 rows replaced by average):

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/average_resized_car.jpg)

Example result (all rows replaced by their average):

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/average_rows.jpg)

Example result (all columns replaced by their average):

![alt](http://www.weheartcv.com/wp-content/uploads/2014/12/average_cols.jpg)

[Solution](https://github.com/perticascatalin/1.1-Understanding-an-Image/blob/master/exercises/average.py)